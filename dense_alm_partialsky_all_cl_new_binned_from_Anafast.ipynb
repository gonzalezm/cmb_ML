{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= int(time.time())#20#0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "session_conf.gpu_options.allow_growth = True\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camb\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, Dropout, Input, Flatten, Conv1D, Lambda\n",
    "from keras.layers import concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from create_training_data_clean import *\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for the healpix map\n",
    "nside = 128\n",
    "npix = 12 * nside ** 2\n",
    "nl = 2 * nside\n",
    "lmax = nl - 1\n",
    "nalm = int(nl * (nl + 1) / 2)\n",
    "new_lmax = lmax-1\n",
    "\n",
    "#Number of Training models\n",
    "nbmodels = 200000\n",
    "\n",
    "#White Noise\n",
    "noise_rms = 0#200\n",
    "noisy_bool = noise_rms != 0\n",
    "\n",
    "#Partial sky\n",
    "f_sky = 0.02\n",
    "\n",
    "#Binning\n",
    "lmin = 20\n",
    "delta_ell = 16\n",
    "nl = nl - lmin\n",
    "\n",
    "#Selecting spectrum\n",
    "spectrum = \"BB\"\n",
    "clnames = ['TT', 'EE', 'BB', 'TE']\n",
    "idx_cell = clnames.index(spectrum)\n",
    "\n",
    "#Data path\n",
    "path_dir_data = \"data_PartialSky_100/\"\n",
    "if noisy_bool:\n",
    "    path_dir_data = path_dir_data + \"_noise\"\n",
    "path_dir_data = path_dir_data + \"/\"\n",
    "\n",
    "base_data_file = path_dir_data + \"data_file_partial_sky_nside_{}_100\".format(nside)\n",
    "\n",
    "data_filename = base_data_file + \"_0.pickle\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "batch_size = 2000#500#0\n",
    "n_epochs = 4000#30#400\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Architecture\n",
    "dropout_val = 0.5\n",
    "n_hidden_layer = 2\n",
    "\n",
    "#Training\n",
    "training_fraction = 0.8\n",
    "mult_fact = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path + \"_{}_layer\".format(n_hidden_layer)\n",
    "if n_hidden_layer > 1:\n",
    "    path = path + \"s\"\n",
    "if dropout_val > 0:\n",
    "    path = path + \"_dropout\"\n",
    "if noisy_bool:\n",
    "    path = path + \"_noise\"\n",
    "\n",
    "path = path + \"_{}_{}_{}_epochs_{}_out_x{}_binned_from_anafast\".format(lmin, new_lmax, n_epochs, spectrum, mult_fact)\n",
    "\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating/Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating input spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_camb = CreateCosmology(nside,lmax)\n",
    "#cl_camb = cl_camb[lmin:lmax+1]\n",
    "print(cl_camb.shape)\n",
    "\n",
    "ll = np.arange(lmin, lmax+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data and stores it into files\n",
    "if not os.path.isfile(data_filename):\n",
    "    for i in range(nbmodels//100):\n",
    "        [all_cl_theo_binned_trans, all_alm_ana_trans, all_dl_namaster_trans, all_cl_anafast_binned_trans] = CreateModelsSmoothSpectra(100, nl, npix, nalm, nside, lmin, lmax, cl_camb, noise_rms = noise_rms, plot_some_spectra=False, delta_ell = delta_ell, f_sky = f_sky)\n",
    "\n",
    "        #\"\"\"\n",
    "        if not os.path.isdir(path_dir_data):\n",
    "            os.mkdir(path_dir_data)\n",
    "        data_filename = base_data_file + \"_{}.pickle\".format(i)\n",
    "        data_file = open(data_filename, \"wb\")\n",
    "        pickle.dump([all_cl_theo_binned_trans, all_alm_ana_trans, all_dl_namaster_trans, all_cl_anafast_binned_trans], data_file)\n",
    "        data_file.close()\n",
    "        #\"\"\"\n",
    "\n",
    "# load generated data\n",
    "all_cl_theo_binned, all_alm_ana, all_dl_namaster, all_cl_anafast_binned = np.array([]), np.array([]), np.array([]), np.array([])\n",
    "for i in range(len(os.listdir(path_dir_data))):\n",
    "    data_filename = base_data_file + \"_{}.pickle\".format(i)\n",
    "    try:\n",
    "        data_file = open(data_filename, \"rb\")\n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        [all_cl_theo_binned_trans, all_alm_ana_trans, all_dl_namaster_trans] = pickle.load(data_file)\n",
    "    except:\n",
    "        data_file.close()\n",
    "        data_file = open(data_filename, \"rb\")\n",
    "        [all_cl_theo_binned_trans, all_alm_ana_trans, all_dl_namaster_trans, all_cl_anafast_binned_trans] = pickle.load(data_file)\n",
    "    if idx_cell < 3: # TT, EE or BB \n",
    "        all_cl_theo_binned_trans, all_alm_ana_trans, all_dl_namaster_trans = all_cl_theo_binned_trans[idx_cell], all_alm_ana_trans[idx_cell], all_dl_namaster_trans[idx_cell]\n",
    "        try:\n",
    "            all_cl_anafast_binned_trans = all_cl_anafast_binned_trans[idx_cell]\n",
    "        except:\n",
    "            all_cl_anafast_binned_trans = np.array([])\n",
    "    else: # We need alm of T and E\n",
    "        print(\"idx_cell >= 3 not implemented\")\n",
    "        #exit()\n",
    "        all_cl_theo_binned_trans, all_alm_ana_trans, all_dl_namaster_trans = all_cl_theo_binned_trans[idx_cell], all_alm_ana_trans[0], all_dl_namaster_trans[idx_cell]\n",
    "        try:\n",
    "            all_cl_anafast_binned_trans = all_cl_anafast_binned_trans[idx_cell]\n",
    "        except:\n",
    "            all_cl_anafast_binned_trans = np.array([])\n",
    "    if i == 0:\n",
    "        all_cl_theo_binned = all_cl_theo_binned_trans.copy()\n",
    "        print(all_cl_theo_binned.shape)\n",
    "        all_cl_theo_binned_trans = []\n",
    "        all_alm_ana = all_alm_ana_trans.copy()\n",
    "        all_alm_ana_trans = []\n",
    "        all_dl_namaster = all_dl_namaster_trans.copy()\n",
    "        all_dl_namaster_trans = []\n",
    "        all_cl_anafast_binned = all_cl_anafast_binned_trans.copy()\n",
    "        all_cl_anafast_binned_trans = []\n",
    "    else:\n",
    "        all_cl_theo_binned = np.append(all_cl_theo_binned, all_cl_theo_binned_trans, axis=0)\n",
    "        all_cl_theo_binned_trans = []\n",
    "        all_alm_ana = np.append(all_alm_ana, all_alm_ana_trans, axis=0)\n",
    "        all_alm_ana_trans = []\n",
    "        all_dl_namaster = np.append(all_dl_namaster, all_dl_namaster_trans, axis=0)\n",
    "        all_dl_namaster_trans = []\n",
    "        all_cl_anafast_binned = np.append(all_cl_anafast_binned, all_cl_anafast_binned_trans, axis=0)\n",
    "        all_cl_anafast_binned_trans = []\n",
    "    data_file.close()\n",
    "    if all_cl_theo_binned.shape[0] >= nbmodels:\n",
    "        break\n",
    "\n",
    "print(all_cl_theo_binned.shape)\n",
    "\n",
    "\n",
    "ell_bined = get_ell_binned(nside, lmin, lmax, delta_ell)\n",
    "print(ell_bined.shape)\n",
    "\n",
    "n_bins = ell_bined.shape[-1]\n",
    "print(n_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cl_noise = np.zeros(all_cl_theo_binned.shape) + noise_rms**2*4*np.pi/npix\n",
    "\n",
    "print(all_cl_theo_binned.shape, all_cl_noise.shape, all_dl_namaster.shape, ll.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing last value (biased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dl_namaster = all_dl_namaster[:, :-1]\n",
    "all_cl_noise = all_cl_noise[:, :-1]\n",
    "all_cl_theo_binned = all_cl_theo_binned[:, :-1]\n",
    "if noisy_bool:\n",
    "    all_cl_anafast_binned = all_cl_anafast_binned[:, :-1]\n",
    "ell_bined = ell_bined[:-1]\n",
    "n_bins = n_bins - 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Set max number of realization to keep (memory issue)\n",
    "nbmodels_max = 10000 #7000\n",
    "\n",
    "print(all_cl_theo_binned.shape, all_cl_noise.shape, all_dl_namaster.shape, ll.shape)\n",
    "all_dl_namaster = all_dl_namaster[:nbmodels_max]\n",
    "all_cl_noise = all_cl_noise[:nbmodels_max]\n",
    "all_cl_theo_binned = all_cl_theo_binned[:nbmodels_max]\n",
    "all_alm_ana = all_alm_ana[:nbmodels_max]\n",
    "\n",
    "print(all_cl_theo_binned.shape, all_cl_noise.shape, all_dl_namaster.shape, ll.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting NaMaster Dl to Cl to compare with other spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cl_namaster = all_dl_namaster / (ell_bined * (ell_bined +1)/ (2*np.pi))\n",
    "\n",
    "print(all_cl_theo_binned.shape, all_cl_noise.shape, all_cl_namaster.shape, ll.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Anafast Cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not noisy_bool:\n",
    "    # Calculating Anafast Cl\n",
    "    import healpy as hp\n",
    "    all_cl_anafast_binned = np.zeros(all_cl_theo_binned.shape)\n",
    "    for i, alm_ana in enumerate(all_alm_ana):\n",
    "        cl_anafast = hp.sphtfunc.alm2cl(alm_ana, lmax=lmax)\n",
    "        cl_anafast = cl_anafast.reshape((1, cl_anafast.shape[0]))\n",
    "        cl_anafast_binned = get_binned_spectra(nside, lmin, lmax, delta_ell, cl_anafast)\n",
    "        cl_anafast_binned = cl_anafast_binned[:, :-1]\n",
    "        all_cl_anafast_binned[i, :] = cl_anafast_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test\n",
    "Input data is normalised.\n",
    "The mult_fact factor is a trick to get better performances. It changes the scale of the expected training output (y_train). \n",
    "The neural network will then predict an values of the same scale. To get back to the original scale, we then need to divide the predicted values by the mult_fact factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilim = int(all_cl_theo_binned.shape[0] * training_fraction)\n",
    "print(ilim)\n",
    "\n",
    "mx = np.max(all_cl_anafast_binned)\n",
    "\n",
    "x_train = all_cl_anafast_binned[0:ilim, :] / mx\n",
    "y_train = (all_cl_theo_binned + all_cl_noise)[0:ilim, :]*mult_fact\n",
    "\n",
    "y_test = (all_cl_theo_binned + all_cl_noise)[ilim:, :]\n",
    "x_test = all_cl_anafast_binned[ilim:, :] / mx\n",
    "\n",
    "\"\"\"Sample variance\"\"\"\n",
    "sample_variance_binned = 2/((2*ell_bined +1)*delta_ell*f_sky)*(all_cl_theo_binned + all_cl_noise)**2\n",
    "sample_variance_train_binned = sample_variance_binned[0:ilim, :]*mult_fact**2\n",
    "sample_variance_test_binned = sample_variance_binned[ilim:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "# Dealing with different keras versions\n",
    "try:\n",
    "        adam = optimizers.Adam(learning_rate=learning_rate)\n",
    "except:\n",
    "        adam = optimizers.Adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model\n",
    "Here we will just use a neural network with the same number of neurons in each hidden layer.\n",
    "We got n_bins values as inputs and also n_bins values as outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nalm_model = 300#int(nl * (nl + 1) / 2)#200#500\n",
    "print(nalm_model)\n",
    "\n",
    "input_layer = Input(shape=(n_bins,))\n",
    "hidden = Dense(units=nalm_model*6, activation='relu', kernel_initializer='uniform')(input_layer)\n",
    "\n",
    "# Adding hidden layers\n",
    "for i in range(n_hidden_layer-2):\n",
    "    hidden = Dense(units=nalm_model*6, activation='relu')(hidden)\n",
    "    \n",
    "# Adding Dropout layer just before the last hidden layer \n",
    "if dropout_val > 0:\n",
    "    dropout = Dropout(dropout_val)(hidden)\n",
    "    hidden = Dense(units=nalm_model*6, activation='relu')(dropout)\n",
    "else:\n",
    "    hidden = Dense(units=nalm_model*6, activation='relu')(hidden)\n",
    "\n",
    "output_layer = Dense(units=n_bins, activation='linear')(hidden)\n",
    "\n",
    "model = Model(inputs=input_layer,outputs=output_layer)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating outer model\n",
    "To use sample_variance in the loss function without giving it directly to the network, we need to create another model.\n",
    "Inspired from https://stackoverflow.com/questions/50706160/how-to-define-custom-cost-function-that-depends-on-input-when-using-imagedatagen/50707473#50707473\n",
    "\n",
    "Training this model will also train the original one.\n",
    "\n",
    "We also define are loss here in the innerLoss function: \n",
    "$$\\frac{1}{n_{bins}}\\sum_{n=0}^{n_{bins}}\\frac{(C_{\\ell_{bin},n}^{pred} - C_{\\ell_{bin},n}^{true})^2}{\\sigma_{C_{\\ell_{bin},n}}^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalLoss(true,pred):\n",
    "    return pred\n",
    "\n",
    "def innerLoss(x):\n",
    "    y_pred = x[0] \n",
    "    y_true = x[1]\n",
    "    selected_sample_variance_train = x[2]\n",
    "    if not K.is_tensor(y_pred):\n",
    "        y_pred = K.constant(y_pred)\n",
    "    y_true = K.cast(y_true, y_pred.dtype)\n",
    "    \n",
    "    # full sky case: y_true = mean(y_pred) for Anafast\n",
    "    chi2_loss = K.sum(K.abs(y_pred - y_true)**2/selected_sample_variance_train, axis=-1)/n_bins\n",
    "\n",
    "    error = chi2_loss\n",
    "    return error\n",
    "\n",
    "#this model has three inputs:\n",
    "originalInputs = model.input  \n",
    "yTrueInputs = Input(shape=(n_bins,))\n",
    "sample_variance_Inputs = Input(shape=(n_bins,))\n",
    "\n",
    "#the original outputs will become an input for a custom loss layer\n",
    "originalOutputs = model.output\n",
    "\n",
    "#this layer contains our custom loss\n",
    "loss = Lambda(innerLoss)([originalOutputs, yTrueInputs, sample_variance_Inputs])\n",
    "\n",
    "#outer model\n",
    "outerModel = Model(inputs=[originalInputs, yTrueInputs, sample_variance_Inputs], outputs=loss)\n",
    "\n",
    "outerModel.compile(optimizer=adam, loss=finalLoss)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# load model weights\n",
    "#model.load_weights(\"models_complex_4_layers_conv_alternate_different_norm_early_stop_2000/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining EarlyStopping to restore the best network at the end of the training\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=1000,#200,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = outerModel.fit(x=[x_train, y_train, sample_variance_train_binned],y=y_train,\n",
    "            epochs=n_epochs,\n",
    "            batch_size= batch_size,\n",
    "\t        verbose=1,\n",
    "            validation_split=0.1,\n",
    "            callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"models_PartialSky\"\n",
    "if noisy_bool:\n",
    "    model_dir = model_dir + \"_noise\"\n",
    "model_dir = model_dir + \"_{}_binned_from_anafast\".format(spectrum) \n",
    "if not os.path.isdir(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "\"\"\"\n",
    "# save model and architecture to single file\n",
    "model.save(\"models/model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\"\"\"\n",
    "#\"\"\"\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(model_dir + \"/model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.yscale('log')\n",
    "figname = 'fig_loss.png'\n",
    "dest = os.path.join(path, figname)\n",
    "plt.savefig(dest)  # write image to file\n",
    "plt.clf()\n",
    "\n",
    "print(min(history.history['loss']),\n",
    "      min(history.history['val_loss']),\n",
    "      len(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anafast predictions\n",
    "all_cl_anafast_test = all_cl_anafast_binned[ilim:, :]\n",
    "\n",
    "# NaMaster predictions\n",
    "all_cl_namaster_test = all_cl_namaster[ilim:, :]\n",
    "\n",
    "# Neural Network predictions\n",
    "result = model.predict(x_test, batch_size=128)/mult_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing\n",
    "if spectrum != \"TE\":\n",
    "    result[result < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(sample_variance, Cl_true, Cl_pred):\n",
    "    # chi2\n",
    "    val = np.sum((Cl_pred-Cl_true)**2/sample_variance, axis=-1)/n_bins #sum over \\ell\n",
    "    return val\n",
    "\n",
    "metric_val_namaster = metric(sample_variance_test_binned[: ,:], all_cl_namaster_test[: ,:], y_test[: ,:])\n",
    "metric_val_anafast = metric(sample_variance_test_binned[: ,:], all_cl_anafast_test[: ,:], y_test[: ,:])\n",
    "metric_val_ml = metric(sample_variance_test_binned[: ,:], result[: ,:], y_test[: ,:])\n",
    "\n",
    "print(metric_val_namaster, metric_val_anafast, metric_val_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "def statstr(x):\n",
    "    return '{0:8.3f} +/- {1:8.3f}'.format(np.mean(x), np.std(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=120)\n",
    "plt.hist(metric_val_namaster, bins=10, range=[0, 2], alpha=0.5, label=r'$N_{bins}'+ r' = {}$ NaMaster'.format(n_bins-1) + statstr(metric_val_namaster))\n",
    "plt.hist(metric_val_anafast, bins=10, range=[0, 2], alpha=0.5, label=r'$N_{bins}'+ r' = {}$ Anafast'.format(n_bins-1) + statstr(metric_val_anafast))\n",
    "plt.hist(metric_val_ml, bins=10, range=[0, 2], alpha=0.5, label=r'$N_{bins}'+ r' = {}$ ML '.format(n_bins-1) + statstr(metric_val_ml))\n",
    "plt.legend()\n",
    "plt.xlabel(r\"$\\chi^2 metric$\")\n",
    "plt.ylabel(r\"\")\n",
    "plt.title(spectrum)\n",
    "figname = 'fig_chi2_metric.png'\n",
    "dest = os.path.join(path, figname)\n",
    "plt.savefig(dest, bbox_inches='tight')  # write image to file\n",
    "#plt.show()\n",
    "\n",
    "plt.figure(dpi=120)\n",
    "plt.hist(metric_val_namaster, bins=10, range=[0, 50], alpha=0.5, label=r'$N_{bins}'+ r' = {}$ NaMaster'.format(n_bins-1) + statstr(metric_val_namaster))\n",
    "plt.legend()\n",
    "plt.xlabel(r\"$\\chi^2 metric$\")\n",
    "plt.ylabel(r\"\")\n",
    "plt.title(spectrum)\n",
    "figname = 'fig_chi2_metric_namaster.png'\n",
    "dest = os.path.join(path, figname)\n",
    "plt.savefig(dest, bbox_inches='tight')  # write image to file\n",
    "#plt.show()\n",
    "\n",
    "plt.figure(dpi=120)\n",
    "plt.hist(metric_val_anafast, bins=10, range=[0, 50], alpha=0.5, label=r'$N_{bins}'+ r' = {}$ Anafast'.format(n_bins-1) + statstr(metric_val_anafast))\n",
    "plt.legend()\n",
    "plt.xlabel(r\"$\\chi^2 metric$\")\n",
    "plt.ylabel(r\"\")\n",
    "plt.title(spectrum)\n",
    "figname = 'fig_chi2_metric_anafast.png'\n",
    "dest = os.path.join(path, figname)\n",
    "plt.savefig(dest, bbox_inches='tight')  # write image to file\n",
    "#plt.show()\n",
    "\n",
    "plt.figure(dpi=120)\n",
    "plt.hist(metric_val_ml, bins=10, range=[max(np.mean(metric_val_ml)-np.std(metric_val_ml), 0), min(np.mean(metric_val_ml)+np.std(metric_val_ml), 1.5*np.mean(metric_val_ml))], alpha=0.5, label=r'$N_{bins}'+ r' = {}$ ML '.format(n_bins-1) + statstr(metric_val_ml))\n",
    "plt.legend()\n",
    "plt.xlabel(r\"$\\chi^2 metric$\")\n",
    "plt.ylabel(r\"\")\n",
    "plt.title(spectrum)\n",
    "plt.xlim(max(np.mean(metric_val_ml)-np.std(metric_val_ml), 0), min(np.mean(metric_val_ml)+np.std(metric_val_ml), 1.5*np.mean(metric_val_ml)))\n",
    "figname = 'fig_chi2_metric_ml.png'\n",
    "dest = os.path.join(path, figname)\n",
    "plt.savefig(dest, bbox_inches='tight')  # write image to file\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    plt.figure(dpi=120)\n",
    "    plt.plot(ell_bined, ell_bined * (ell_bined + 1) / (2*np.pi) * y_test[i, :], label='Binned input spectra + noise')\n",
    "    plt.plot(ell_bined, ell_bined * (ell_bined + 1) / (2*np.pi) * all_cl_namaster_test[i, :], label='NaMaster')\n",
    "    plt.plot(ell_bined, ell_bined * (ell_bined + 1) / (2*np.pi) * all_cl_anafast_test[i, :], label='Anafast')\n",
    "    plt.plot(ell_bined, ell_bined * (ell_bined + 1) / (2*np.pi) * result[i, :], label='ML')\n",
    "    plt.xlabel(r\"$\\ell$\")\n",
    "    text = r\"$D_{\\ell}^{\" + spectrum + r\"}$\"\n",
    "    plt.ylabel(text)\n",
    "    plt.title(spectrum)\n",
    "    plt.legend()\n",
    "    figname = 'fig_prediction{}.png'.format(i)\n",
    "    dest = os.path.join(path, figname)\n",
    "    plt.savefig(dest, bbox_inches='tight')  # write image to file\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"mectrics.txt\"\n",
    "dest = os.path.join(path, filename)\n",
    "f = open(dest, \"w\")\n",
    "f.write(\"nbmodels: {}\\n\".format(nbmodels))\n",
    "f.write(\"NaMaster: {}\\n\".format(statstr(metric_val_namaster)))\n",
    "f.write(\"Anafast: {}\\n\".format(statstr(metric_val_anafast)))\n",
    "f.write(\"ML: {}\\n\".format(statstr(metric_val_ml)))\n",
    "f.write(\"ML min training loss: {}\\n\".format(min(history.history['loss'])))\n",
    "f.write(\"ML min validation loss: {}\\n\".format(min(history.history['val_loss'])))\n",
    "f.close()\n",
    "\n",
    "filename = \"parameters.txt\"\n",
    "dest = os.path.join(path, filename)\n",
    "f = open(dest, \"w\")\n",
    "f.write(\"batch_size: {}\\n\".format(batch_size))\n",
    "f.write(\"n_epochs: {}\\n\".format(n_epochs))\n",
    "f.write(\"learning_rate: {}\\n\".format(learning_rate))\n",
    "f.write(\"nside: {}\\n\".format(nside))\n",
    "f.write(\"npix: {}\\n\".format(npix))\n",
    "f.write(\"nl: {}\\n\".format(nl))\n",
    "f.write(\"lmax: {}\\n\".format(lmax))\n",
    "f.write(\"nalm: {}\\n\".format(nalm))\n",
    "f.write(\"nbmodels: {}\\n\".format(nbmodels))\n",
    "f.write(\"n_training: {}\\n\".format(int(0.9*ilim)))\n",
    "f.write(\"n_testing: {}\\n\".format(x_test.shape[0]))\n",
    "f.write(\"nbmodels: {}\\n\".format(nbmodels))\n",
    "f.write(\"new_lmax: {}\\n\".format(new_lmax))\n",
    "f.write(\"n_bins: {}\\n\".format(n_bins))\n",
    "f.write(\"training_fraction: {}\\n\".format(training_fraction))\n",
    "f.write(\"stopped at epoch: {}\\n\".format(len(history.history['loss'])))\n",
    "f.write(\"noise_rms: {}\\n\".format(noise_rms))\n",
    "f.write(\"mult_fact: {}\\n\".format(mult_fact))\n",
    "f.write(\"nalm_model: {}\\n\".format(nalm_model))\n",
    "f.write(\"seed_value: {}\\n\".format(seed_value))\n",
    "f.write(\"dropout_val: {}\\n\".format(dropout_val))\n",
    "f.close()\n",
    "\n",
    "filename = \"log_perf_from_anafast.txt\"\n",
    "f = open(filename, \"a\")\n",
    "f.write(\"\\n{}, {}, {}, {}, {}, {}, {}, {}, True\".format(nalm_model, statstr(metric_val_ml), seed_value, int(0.9*ilim), x_test.shape[0], dropout_val, spectrum, mult_fact))\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean and variance of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_camb = CreateCosmology(nside,lmax)\n",
    "\n",
    "n_new_x_test = 1000\n",
    "\n",
    "path_dir_data = \"data_PartialSky_100_new_test\"\n",
    "if noisy_bool:\n",
    "    path_dir_data = path_dir_data + \"_noise\"\n",
    "path_dir_data = path_dir_data + \"/\"\n",
    "\n",
    "base_data_file = path_dir_data + \"data_file_partial_sky_nside_{}_100_new_test\".format(nside)\n",
    "\n",
    "data_filename = base_data_file + \"_0.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a partial map\n",
    "def CreateAnafastPartialSky_(cl, nside, lmin, lmax, delta_ell, f_sky = 2/100, plot_results = False, noise_rms = 200):\n",
    "    import NamasterLib as nam\n",
    "    # Determine SEEN pixels from f_sky using query_disc\n",
    "    vec = hp.pixelfunc.ang2vec(np.pi/2, np.pi*3/4)\n",
    "    radius = f_sky*np.pi\n",
    "\n",
    "    #print(np.array([cl.T[0,:]]).shape)\n",
    "\n",
    "    ipix_disc = hp.query_disc(nside=nside, vec=vec, radius=radius, nest=False)\n",
    "    while len(ipix_disc) < f_sky*12*nside**2:\n",
    "\t    radius += 0.01*np.pi\n",
    "\t    ipix_disc = hp.query_disc(nside=nside, vec=vec, radius=radius, nest=False)\n",
    "    #print(\"npix_partial_sky: \", len(ipix_disc))\n",
    "\n",
    "    m = np.arange(12 * nside**2)\n",
    "    m = np.delete(m, ipix_disc, axis=None)\n",
    "\n",
    "    # Define the seen pixels\n",
    "    seenpix = ipix_disc\n",
    "\n",
    "    ### Making mask - it will be automaticall apodized when instanciating the object with default (tunable) parameters\n",
    "    mask = np.zeros(12 * nside**2)\n",
    "    mask[seenpix] = 1\n",
    "    Namaster = nam.Namaster(mask, lmin=lmin, lmax=lmax, delta_ell=delta_ell)\n",
    "\n",
    "    ell_binned, b = Namaster.get_binning(nside)\n",
    "    # Get binned input spectra\n",
    "    cl_theo_binned = np.zeros(shape=(4, ell_binned.shape[0]))\n",
    "    for i in range(4):\n",
    "\t    cl_theo_binned[i, :] = Namaster.bin_spectra(np.array([cl.T[i, :]]), nside)\n",
    "\n",
    "    map_ = hp.synfast(cl.T, nside, pixwin=False, verbose=False, new = True)\n",
    "    npix = 12 * nside ** 2\n",
    "    noise = np.random.randn(npix)*noise_rms\n",
    "    map_partial = map_ + noise\n",
    "\n",
    "    # Anafast spectrum of this map\n",
    "    # Set UNSEEN pixels to hp.UNSEEN for Anafast\n",
    "    map_partial[:, m] = hp.UNSEEN\n",
    "    cl_ana, alm_ana = hp.anafast(map_partial, alm=True, lmax=lmax)\n",
    "\n",
    "    # Get binned input spectra\n",
    "    cl_ana_binned = np.zeros(shape=(4, ell_binned.shape[0]))\n",
    "    for i in range(4):\n",
    "        cl_ana_binned[i, :] = Namaster.bin_spectra(np.array([cl_ana[i, :]]), nside)\n",
    "\n",
    "    return alm_ana, cl_ana_binned, cl_theo_binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_type='Linear'\n",
    "\n",
    "#all_cl_anafast_binned_new_test = np.zeros(shape=(n_new_x_test, n_bins))\n",
    "#all_cl_theo_binned_new_test = np.zeros(shape=(n_new_x_test, n_bins))\n",
    "\n",
    "theshape = Shape(shape_type, lmax, np.arange(0, lmax+1))\n",
    "theshape_ = np.ones(cl_camb.shape)\n",
    "for l in range(cl_camb.shape[0]):\n",
    "    theshape_[l, :] = theshape_[l, :]*theshape[l]\n",
    "\n",
    "# store/load the generated data into/from a file\n",
    "if not os.path.isfile(data_filename):\n",
    "        for i in range(n_new_x_test//100):\n",
    "            all_alm_ana_trans, all_cl_anafast_binned_trans, all_cl_theo_binned_trans = np.zeros(shape=(3, 100, nalm))*1j, np.zeros(shape=(4, 100, n_bins + 1)), np.zeros(shape=(4, 100, n_bins + 1))\n",
    "            for j in range(100):\n",
    "                [alm_ana, cl_ana_binned, cl_theo_binned] = CreateAnafastPartialSky_(cl_camb * theshape_, nside, lmin, lmax, delta_ell, f_sky = f_sky, noise_rms = noise_rms)              \n",
    "                if j == 0:\n",
    "                    print(i*100)\n",
    "                all_cl_theo_binned_trans[:, j, :] = cl_theo_binned\n",
    "                all_alm_ana_trans[:, j, :] = alm_ana\n",
    "                all_cl_anafast_binned_trans[:, j, :] = cl_ana_binned\n",
    "            #\"\"\"\n",
    "            if not os.path.isdir(path_dir_data):\n",
    "                os.mkdir(path_dir_data)\n",
    "            data_filename = base_data_file + \"_{}.pickle\".format(i)\n",
    "            data_file = open(data_filename, \"wb\")\n",
    "            pickle.dump([all_cl_theo_binned_trans, all_alm_ana_trans, all_cl_anafast_binned_trans], data_file)\n",
    "            data_file.close()\n",
    "            #\"\"\"\n",
    "\n",
    "all_cl_theo_binned_new_test, all_alm_ana_new_test, all_cl_anafast_binned_new_test = np.array([]), np.array([]), np.array([])\n",
    "for i in range(len(os.listdir(path_dir_data))):\n",
    "    data_filename = base_data_file + \"_{}.pickle\".format(i)\n",
    "    try:\n",
    "        data_file = open(data_filename, \"rb\")\n",
    "    except:\n",
    "        continue\n",
    "    [all_cl_theo_binned_trans, all_alm_ana_trans, all_cl_anafast_binned_trans] = pickle.load(data_file)\n",
    "    if idx_cell < 3: # TT, EE or BB \n",
    "        all_cl_theo_binned_trans, all_alm_ana_trans, all_cl_anafast_binned_trans = all_cl_theo_binned_trans[idx_cell], all_alm_ana_trans[idx_cell], all_cl_anafast_binned_trans[idx_cell]\n",
    "    else: # We need alm of T and E\n",
    "        print(\"idx_cell >= 3 not implemented\")\n",
    "        all_cl_theo_binned_trans, all_alm_ana_trans, all_cl_anafast_binned_trans = all_cl_theo_binned_trans[idx_cell], all_alm_ana_trans[0], all_cl_anafast_binned_trans[idx_cell]\n",
    "        #exit()\n",
    "    if i == 0:\n",
    "        all_cl_theo_binned_new_test = all_cl_theo_binned_trans.copy()\n",
    "        print(all_cl_theo_binned_new_test.shape)\n",
    "        all_cl_theo_binned_trans = []\n",
    "        all_alm_ana_new_test = all_alm_ana_trans.copy()\n",
    "        all_alm_ana_trans = []\n",
    "        all_cl_anafast_binned_new_test = all_cl_anafast_binned_trans.copy()\n",
    "        all_cl_anafast_binned_trans = []\n",
    "    else:\n",
    "        all_cl_theo_binned_new_test = np.append(all_cl_theo_binned_new_test, all_cl_theo_binned_trans, axis=0)\n",
    "        all_cl_theo_binned_trans = []\n",
    "        all_alm_ana_new_test = np.append(all_alm_ana_new_test, all_alm_ana_trans, axis=0)\n",
    "        all_alm_ana_trans = []\n",
    "        all_cl_anafast_binned_new_test = np.append(all_cl_anafast_binned_new_test, all_cl_anafast_binned_trans, axis=0)\n",
    "        all_cl_anafast_binned_trans = []\n",
    "        print(all_cl_anafast_binned_new_test)\n",
    "    data_file.close()\n",
    "    if all_cl_theo_binned_new_test.shape[0] >= n_new_x_test:\n",
    "        break\n",
    "\n",
    "print(all_cl_anafast_binned_new_test.shape)\n",
    "# Removing last value (biased)\n",
    "all_cl_theo_binned_new_test = all_cl_theo_binned_new_test[:, :-1]\n",
    "all_cl_anafast_binned_new_test = all_cl_anafast_binned_new_test[:, :-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x_test = all_cl_anafast_binned_new_test / mx\n",
    "new_y_test = all_cl_theo_binned_new_test + noise_rms**2*4*np.pi/npix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network predictions\n",
    "result = model.predict(new_x_test, batch_size=128)/mult_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_result_np = np.mean(result, axis=0)\n",
    "std_result_np = np.std(result, axis=0)\n",
    "#\"\"\"\n",
    "mean_result = np.zeros(n_bins)\n",
    "for i in range(n_new_x_test):\n",
    "    mean_result += result[i, :]\n",
    "mean_result /= n_new_x_test\n",
    "print(mean_result_np-mean_result)\n",
    "std_result = np.zeros(n_bins)\n",
    "for i in range(n_new_x_test):\n",
    "    std_result += (result[i, :]-mean_result)**2\n",
    "std_result = np.sqrt(std_result/n_new_x_test)\n",
    "#\"\"\"\n",
    "sample_variance_binned_new_test = 2/((2*ell_bined +1)*delta_ell*f_sky)*new_y_test**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=120)\n",
    "if noisy_bool:\n",
    "    plt.plot(ell_bined, ell_bined * (ell_bined + 1) / (2*np.pi) * new_y_test[0, :], label='Binned input spectra + noise')\n",
    "else:\n",
    "    plt.plot(ell_bined, ell_bined * (ell_bined + 1) / (2*np.pi) * new_y_test[0, :], label='Binned input spectra')\n",
    "\n",
    "#plt.plot(ell_bined, ell_bined * (ell_bined + 1) / (2*np.pi) * all_cl_namaster_test[i, :], label='NaMaster')\n",
    "plt.errorbar(ell_bined, ell_bined * (ell_bined + 1) / (2*np.pi) * mean_result, yerr = ell_bined * (ell_bined + 1) / (2*np.pi) * std_result, fmt='m.', label='Mean ML')\n",
    "plt.errorbar(ell_bined+2, ell_bined * (ell_bined + 1) / (2*np.pi) * new_y_test[0, :], yerr = ell_bined * (ell_bined + 1) / (2*np.pi) * np.sqrt(sample_variance_binned_new_test)[0, :], fmt='b.', label='Sample variance')\n",
    "\n",
    "plt.xlabel(r\"$\\ell$\")\n",
    "text = r\"$D_{\\ell}^{\" + spectrum + r\"}$\"\n",
    "plt.ylabel(text)\n",
    "plt.title(spectrum)\n",
    "plt.legend()\n",
    "figname = 'fig_prediction_mean.png'\n",
    "dest = os.path.join(path, figname)\n",
    "plt.savefig(dest, bbox_inches='tight')  # write image to file\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
