{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= int(time.time())#20#0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "session_conf.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camb\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, Dropout, Input, Flatten, Conv1D, Lambda\n",
    "from keras.layers import concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from create_training_data_clean import *\n",
    "import os\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for the healpix map\n",
    "nside = 16\n",
    "npix = 12 * nside ** 2\n",
    "nl = 2 * nside\n",
    "lmax = nl - 1\n",
    "nalm = int(nl * (nl + 1) / 2)\n",
    "lmin = 0 # Added by Me\n",
    "\n",
    "# Number of Training models\n",
    "nbmodels = 200000\n",
    "\n",
    "#White Noise\n",
    "noise_rms = 200\n",
    "noisy_bool = noise_rms != 0\n",
    "\n",
    "new_lmin = 2\n",
    "if noisy_bool:\n",
    "    new_lmax = lmax\n",
    "else:\n",
    "    new_lmax = lmax-1\n",
    "\n",
    "nl_used = nl - ((new_lmin + (lmax-new_lmax)))\n",
    "\n",
    "#Selecting spectrum\n",
    "spectrum = \"BB\"\n",
    "clnames = ['TT', 'EE', 'BB', 'TE']\n",
    "idx_cell = clnames.index(spectrum)\n",
    "\n",
    "#Data path\n",
    "path_dir_data = \"data_FullSky\"\n",
    "if noisy_bool:\n",
    "    path_dir_data = path_dir_data + \"_noise\"\n",
    "path_dir_data = path_dir_data + \"/\"\n",
    "\n",
    "base_data_file = path_dir_data + \"data_file_{}_10000\".format(nside)\n",
    "\n",
    "data_filename = base_data_file + \"_0.pickle\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "batch_size = 5000\n",
    "n_epochs = 400#30#400\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Architecture\n",
    "dropout_val = 0.5\n",
    "n_hidden_layer = 2\n",
    "\n",
    "#Training\n",
    "training_fraction = 0.8\n",
    "mult_fact = 1e1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path_ + \"_{}_layer\".format(n_hidden_layer) # Modified by me\n",
    "if n_hidden_layer > 1:\n",
    "    path = path + \"s\"\n",
    "if dropout_val > 0:\n",
    "    path = path + \"_dropout\"\n",
    "if noisy_bool:\n",
    "    path = path + \"_noise\"\n",
    "\n",
    "path = path + \"_{}_{}_{}_epochs_{}_out_x{}\".format(lmin, new_lmax, n_epochs, spectrum, mult_fact)\n",
    "\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating/Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating input spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total\n",
      "unlensed_scalar\n",
      "unlensed_total\n",
      "lensed_scalar\n",
      "tensor\n",
      "lens_potential\n",
      "kk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gonzalez/anaconda3/lib/python3.8/site-packages/healpy/projaxes.py:920: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. In future versions, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = copy.copy(mpl.cm.get_cmap(\"viridis\"))\n",
      "  newcm.set_over(newcm(1.0))\n",
      "/Users/gonzalez/anaconda3/lib/python3.8/site-packages/healpy/projaxes.py:921: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. In future versions, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = copy.copy(mpl.cm.get_cmap(\"viridis\"))\n",
      "  newcm.set_under(bgcolor)\n",
      "/Users/gonzalez/anaconda3/lib/python3.8/site-packages/healpy/projaxes.py:922: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. In future versions, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = copy.copy(mpl.cm.get_cmap(\"viridis\"))\n",
      "  newcm.set_bad(badcolor)\n",
      "/Users/gonzalez/anaconda3/lib/python3.8/site-packages/healpy/projaxes.py:202: MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax simultaneously is deprecated since 3.3 and will become an error two minor releases later. Please pass vmin/vmax directly to the norm when creating it.\n",
      "  aximg = self.imshow(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kk\n",
      "kk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 612x388.8 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 612x388.8 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 612x388.8 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cl_camb = CreateCosmology(nside,lmax)\n",
    "cl_ana, alm_ana = CreateAnafastFullSky(cl_camb, nside, lmax, noise_rms=nl, plot_results = True)\n",
    "ll = np.arange(nl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n",
      "(200000, 32)\n"
     ]
    }
   ],
   "source": [
    "# generate data and stores it into files\n",
    "if not os.path.isfile(data_filename):\n",
    "    for i in range(nbmodels//10000):\n",
    "        print(i,'GO')\n",
    "        all_cl_theo, all_alm_ana, all_cl_ana = CreateModelsSmoothSpectra(10000, nl, npix, nalm, nside, lmin, lmax, cl_camb, noise_rms = noise_rms, plot_some_spectra=False)\n",
    "        \n",
    "        #\"\"\"\n",
    "        print(i,'OK')\n",
    "        if not os.path.isdir(path_dir_data):\n",
    "            os.mkdir(path_dir_data)\n",
    "        data_filename = base_data_file + \"_{}.pickle\".format(i)\n",
    "        data_file = open(data_filename, \"wb\")\n",
    "        pickle.dump([all_cl_theo, all_alm_ana, all_cl_ana], data_file)\n",
    "        data_file.close()\n",
    "        #\"\"\"\n",
    "\n",
    "        # load generated data\n",
    "all_cl_theo, all_alm_ana, all_cl_ana = np.array([]), np.array([]), np.array([])\n",
    "for i in range(len(os.listdir(path_dir_data))):\n",
    "    data_filename = base_data_file + \"_{}.pickle\".format(i)\n",
    "    try:\n",
    "        data_file = open(data_filename, \"rb\")\n",
    "    except:\n",
    "        continue\n",
    "    [all_cl_theo_trans, all_alm_ana_trans, all_cl_ana_trans] = pickle.load(data_file)\n",
    "    if idx_cell < 3: # TT, EE or BB \n",
    "        all_cl_theo_trans, all_alm_ana_trans, all_cl_ana_trans = all_cl_theo_trans[idx_cell], all_alm_ana_trans[idx_cell], all_cl_ana_trans[idx_cell]\n",
    "    else: # We need alm of T and E\n",
    "        print(\"idx_cell >= 3 not implemented\")\n",
    "        exit()\n",
    "        all_cl_theo_trans, all_alm_ana_trans, all_cl_ana_trans = all_cl_theo_trans[idx_cell], all_alm_ana_trans[0], all_cl_ana_trans[idx_cell]\n",
    "    if i == 0:\n",
    "        all_cl_theo = all_cl_theo_trans.copy()\n",
    "        print(all_cl_theo.shape)\n",
    "        all_cl_theo_trans = []\n",
    "        all_alm_ana = all_alm_ana_trans.copy()\n",
    "        all_alm_ana_trans = []\n",
    "        all_cl_ana = all_cl_ana_trans.copy()\n",
    "        all_cl_ana_trans = []\n",
    "    else:\n",
    "        all_cl_theo = np.append(all_cl_theo, all_cl_theo_trans, axis=0)\n",
    "        all_cl_theo_trans = []\n",
    "        all_alm_ana = np.append(all_alm_ana, all_alm_ana_trans, axis=0)\n",
    "        all_alm_ana_trans = []\n",
    "        all_cl_ana = np.append(all_cl_ana, all_cl_ana_trans, axis=0)\n",
    "        all_cl_ana_trans = []\n",
    "    data_file.close()\n",
    "    if all_cl_theo.shape[0] >= nbmodels:\n",
    "        break\n",
    "\n",
    "print(all_cl_theo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cl_noise = np.zeros(all_cl_theo.shape) + noise_rms**2*4*np.pi/npix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting $\\ell$ range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 28)\n"
     ]
    }
   ],
   "source": [
    "all_cl_theo = all_cl_theo[:, new_lmin:new_lmax+1]\n",
    "all_cl_noise = all_cl_noise[:, new_lmin:new_lmax+1]\n",
    "all_cl_ana = all_cl_ana[:, new_lmin:new_lmax+1]\n",
    "ll = ll[new_lmin:new_lmax+1]\n",
    "\n",
    "print(all_cl_theo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "Inputs alm real and imaginary parts are normalised separatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-01ac792ad4ed>:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  all_alm_ana = np.stack((all_alm_ana.real/max_alm_real, all_alm_ana.imag/max_alm_imag), axis=-1)\n"
     ]
    }
   ],
   "source": [
    "max_alm_real = np.max(np.abs(all_alm_ana.real))\n",
    "max_alm_imag = np.max(np.abs(all_alm_ana.imag))\n",
    "all_alm_ana = np.stack((all_alm_ana.real/max_alm_real, all_alm_ana.imag/max_alm_imag), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test\n",
    "The mult_fact factor is a trick to get better performances. It changes the scale of the expected training output (y_train). \n",
    "The neural network will then predict an values of the same scale. To get back to the original scale, we then need to divide the predicted values by the mult_fact factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "ilim = int(all_cl_theo.shape[0] * training_fraction)\n",
    "print(ilim)\n",
    "\n",
    "x_train = all_alm_ana[0:ilim, :]\n",
    "y_train = (all_cl_theo + all_cl_noise)[0:ilim, :]*mult_fact\n",
    "\n",
    "y_test = (all_cl_theo + all_cl_noise)[ilim:, :]\n",
    "x_test = all_alm_ana[ilim:, :]\n",
    "\n",
    "\"\"\"Sample variance\"\"\"\n",
    "sample_variance = 2/(2*ll +1)*(all_cl_theo + all_cl_noise)**2\n",
    "sample_variance_train = sample_variance[0:ilim, :]*mult_fact**2\n",
    "sample_variance_test = sample_variance[ilim:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.optimizers' has no attribute 'Adam'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-50120178753b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0madam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.optimizers' has no attribute 'Adam'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-50120178753b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0madam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0madam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.optimizers' has no attribute 'Adam'"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "# Dealing with different keras versions\n",
    "try:\n",
    "        adam = optimizers.Adam(learning_rate=learning_rate)\n",
    "except:\n",
    "        adam = optimizers.Adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model\n",
    "Here we will use a neural network with the same number of neurons in each hidden layer.\n",
    "We also add a Conv1D layer to tell the network to treat real and imaginary parts of each alm together. \n",
    "We got two times nalm values as inputs (real and imaginary part of each alm) and nl_used values as outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nalm_model = nalm\n",
    "print(nalm_model)\n",
    "\n",
    "input_layer = Input(shape=(nalm,2))\n",
    "conv_layer = Conv1D(filters=1, kernel_size=2)(input_layer)\n",
    "flatten = Flatten()(conv_layer)\n",
    "hidden = Dense(units=nalm_model*6, activation='relu', kernel_initializer='uniform')(input_layer)\n",
    "\n",
    "# Adding hidden layers\n",
    "for i in range(n_hidden_layer-2):\n",
    "    hidden = Dense(units=nalm_model*6, activation='relu')(hidden)\n",
    "    \n",
    "# Adding Dropout layer just before the last hidden layer \n",
    "if dropout_val > 0:\n",
    "    dropout = Dropout(dropout_val)(hidden)\n",
    "    hidden = Dense(units=nalm_model*6, activation='relu')(dropout)\n",
    "else:\n",
    "    hidden = Dense(units=nalm_model*6, activation='relu')(hidden)\n",
    "\n",
    "output_layer = Dense(units=nl_used, activation='linear')(hidden)\n",
    "\n",
    "model = Model(inputs=input_layer,outputs=output_layer)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating outer model\n",
    "To use sample_variance in the loss function without giving it directly to the network, we need to create another model.\n",
    "Inspired from https://stackoverflow.com/questions/50706160/how-to-define-custom-cost-function-that-depends-on-input-when-using-imagedatagen/50707473#50707473\n",
    "\n",
    "Training this model will also train the original one.\n",
    "\n",
    "We also define are loss here in the innerLoss function: \n",
    "$$\\frac{1}{nl_{used}}\\sum_{n=0}^{nl_{used}}\\frac{(C_{\\ell,n}^{pred} - C_{\\ell,n}^{true})^2}{\\sigma_{C_{\\ell,n}}^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalLoss(true,pred):\n",
    "    return pred\n",
    "\n",
    "def innerLoss(x):\n",
    "    y_pred = x[0] \n",
    "    y_true = x[1]\n",
    "    selected_sample_variance_train = x[2]\n",
    "    if not K.is_tensor(y_pred):\n",
    "        y_pred = K.constant(y_pred)\n",
    "    y_true = K.cast(y_true, y_pred.dtype)\n",
    "    \n",
    "    # full sky case: y_true = mean(y_pred) for Anafast\n",
    "    chi2_loss = K.sum(K.abs(y_pred - y_true)**2/selected_sample_variance_train, axis=-1)/nl_used\n",
    "\n",
    "    error = chi2_loss\n",
    "    return error\n",
    "\n",
    "#this model has three inputs:\n",
    "originalInputs = model.input  \n",
    "yTrueInputs = Input(shape=(nl_used,))\n",
    "sample_variance_Inputs = Input(shape=(nl_used,))\n",
    "\n",
    "#the original outputs will become an input for a custom loss layer\n",
    "originalOutputs = model.output\n",
    "\n",
    "#this layer contains our custom loss\n",
    "loss = Lambda(innerLoss)([originalOutputs, yTrueInputs, sample_variance_Inputs])\n",
    "\n",
    "#outer model\n",
    "outerModel = Model(inputs=[originalInputs, yTrueInputs, sample_variance_Inputs], outputs=loss)\n",
    "\n",
    "outerModel.compile(optimizer=adam, loss=finalLoss)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# load model weights\n",
    "#model.load_weights(\"models_complex_4_layers_conv_alternate_different_norm_early_stop_2000/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining EarlyStopping to restore the best network at the end of the training\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=200,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = outerModel.fit(x=[x_train, y_train, sample_variance_train],y=y_train,\n",
    "            epochs=n_epochs,\n",
    "            batch_size= batch_size,\n",
    "\t        verbose=1,\n",
    "            validation_split=0.1,\n",
    "            callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"models_FullSky\"\n",
    "if noisy_bool:\n",
    "    model_dir = model_dir + \"_noise\"\n",
    "model_dir = model_dir + \"_{}\".format(spectrum) \n",
    "if not os.path.isdir(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "\"\"\"\n",
    "# save model and architecture to single file\n",
    "model.save(\"models/model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\"\"\"\n",
    "#\"\"\"\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(model_dir + \"/model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.yscale('log')\n",
    "figname = 'fig_loss.png'\n",
    "dest = os.path.join(path, figname)\n",
    "plt.savefig(dest)  # write image to file\n",
    "plt.clf()\n",
    "\n",
    "print(min(history.history['loss']),\n",
    "      min(history.history['val_loss']),\n",
    "      len(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anafast predictions\n",
    "all_cl_ana_test = all_cl_ana[ilim:, :]\n",
    "\n",
    "# Neural Network predictions\n",
    "result = model.predict(x_test, batch_size=128)/mult_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing\n",
    "if spectrum != \"TE\":\n",
    "    result[result < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(sample_variance, Cl_true, Cl_pred):\n",
    "    # chi2\n",
    "    val = np.sum((Cl_pred-Cl_true)**2/sample_variance, axis=-1)/nl_used #sum over \\ell\n",
    "    return val\n",
    "\n",
    "metric_val_anafast = metric(sample_variance_test[: ,:], all_cl_ana_test[: ,:], y_test[: ,:])\n",
    "metric_val_ml = metric(sample_variance_test[: ,:], result[: ,:], y_test[: ,:])\n",
    "\n",
    "print(metric_val_namaster, metric_val_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "def statstr(x):\n",
    "    return '{0:8.3f} +/- {1:8.3f}'.format(np.mean(x), np.std(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=120)\n",
    "plt.hist(metric_val_anafast, bins=10, range=[0, 2], alpha=0.5, label=r'$N_\\ell = {}$ Anafast'.format(nl_used) + statstr(metric_val_anafast))\n",
    "plt.hist(metric_val_ml, bins=10, range=[0, 2], alpha=0.5, label=r'$N_\\ell = {}$ ML '.format(nl_used) + statstr(metric_val_ml))\n",
    "plt.legend()\n",
    "plt.xlabel(r\"$\\chi^2 metric$\")\n",
    "plt.ylabel(r\"\")\n",
    "plt.title(spectrum)\n",
    "figname = 'fig_chi2_metric.png'\n",
    "dest = os.path.join(path, figname)\n",
    "plt.savefig(dest, bbox_inches='tight')  # write image to file\n",
    "#plt.show()\n",
    "\n",
    "plt.figure(dpi=120)\n",
    "plt.hist(metric_val_anafast, bins=10, range=[0, 2], alpha=0.5, label=r'$N_\\ell = {}$ Anafast'.format(nl_used) + statstr(metric_val_anafast))\n",
    "plt.legend()\n",
    "plt.xlabel(r\"$\\chi^2 metric$\")\n",
    "plt.ylabel(r\"\")\n",
    "plt.title(spectrum)\n",
    "figname = 'fig_chi2_metric_ana.png'\n",
    "dest = os.path.join(path, figname)\n",
    "plt.savefig(dest, bbox_inches='tight')  # write image to file\n",
    "#plt.show()\n",
    "\n",
    "plt.figure(dpi=120)\n",
    "plt.hist(metric_val_ml, bins=10, range=[max(np.mean(metric_val_ml)-np.std(metric_val_ml), 0), min(np.mean(metric_val_ml)+np.std(metric_val_ml), 1.5*np.mean(metric_val_ml))], alpha=0.5, label=r'$N_\\ell = {}$ ML '.format(nl_used) + statstr(metric_val_ml))\n",
    "plt.legend()\n",
    "plt.xlabel(r\"$\\chi^2 metric$\")\n",
    "plt.ylabel(r\"\")\n",
    "plt.title(spectrum)\n",
    "plt.xlim(max(np.mean(metric_val_ml)-np.std(metric_val_ml), 0), min(np.mean(metric_val_ml)+np.std(metric_val_ml), 1.5*np.mean(metric_val_ml)))\n",
    "figname = 'fig_chi2_metric_ml.png'\n",
    "dest = os.path.join(path, figname)\n",
    "plt.savefig(dest, bbox_inches='tight')  # write image to file\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    plt.figure(dpi=120)\n",
    "    if noisy_bool:\n",
    "        plt.plot(ll, ll * (ll + 1) * y_test[i, :], label='Input spectra + noise')\n",
    "    else:\n",
    "        plt.plot(ll, ll * (ll + 1) * y_test[i, :], label='Input spectra')\n",
    "    plt.plot(ll, ll * (ll + 1) * all_cl_ana_test[i, :], label='Anafast')\n",
    "    plt.plot(ll, ll * (ll + 1) * result[i, :], label='ML')\n",
    "    plt.xlabel(r\"$\\ell$\")\n",
    "    text = r\"$\\ell (\\ell + 1) C_{\\ell}^{\" + spectrum + r\"}$\"\n",
    "    plt.ylabel(text)\n",
    "    plt.title(spectrum)\n",
    "    plt.legend()\n",
    "    figname = 'fig_prediction{}.png'.format(i)\n",
    "    dest = os.path.join(path, figname)\n",
    "    plt.savefig(dest, bbox_inches='tight')  # write image to file\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"mectrics.txt\"\n",
    "dest = os.path.join(path, filename)\n",
    "f = open(dest, \"w\")\n",
    "f.write(\"nbmodels: {}\\n\".format(nbmodels))\n",
    "f.write(\"Anafast: {}\\n\".format(statstr(metric_val_anafast)))\n",
    "f.write(\"ML: {}\\n\".format(statstr(metric_val_ml)))\n",
    "f.write(\"ML min training loss: {}\\n\".format(min(history.history['loss'])))\n",
    "f.write(\"ML min validation loss: {}\\n\".format(min(history.history['val_loss'])))\n",
    "f.close()\n",
    "\n",
    "filename = \"parameters.txt\"\n",
    "dest = os.path.join(path, filename)\n",
    "f = open(dest, \"w\")\n",
    "f.write(\"batch_size: {}\\n\".format(batch_size))\n",
    "f.write(\"n_epochs: {}\\n\".format(n_epochs))\n",
    "f.write(\"learning_rate: {}\\n\".format(learning_rate))\n",
    "f.write(\"nside: {}\\n\".format(nside))\n",
    "f.write(\"npix: {}\\n\".format(npix))\n",
    "f.write(\"nl: {}\\n\".format(nl))\n",
    "f.write(\"lmax: {}\\n\".format(lmax))\n",
    "f.write(\"nalm: {}\\n\".format(nalm))\n",
    "f.write(\"n_training: {}\\n\".format(int(0.9*ilim)))\n",
    "f.write(\"n_testing: {}\\n\".format(x_test.shape[0]))\n",
    "f.write(\"nbmodels: {}\\n\".format(nbmodels))\n",
    "f.write(\"new_lmin: {}\\n\".format(new_lmin))\n",
    "f.write(\"new_lmax: {}\\n\".format(new_lmax))\n",
    "f.write(\"nl_used: {}\\n\".format(nl_used))\n",
    "f.write(\"training_fraction: {}\\n\".format(training_fraction))\n",
    "f.write(\"stopped at epoch: {}\\n\".format(len(history.history['loss'])))\n",
    "f.write(\"noise_rms: {}\\n\".format(noise_rms))\n",
    "f.write(\"mult_fact: {}\\n\".format(mult_fact))\n",
    "f.write(\"nalm_model: {}\\n\".format(nalm_model))\n",
    "f.write(\"seed_value: {}\\n\".format(seed_value))\n",
    "f.write(\"dropout_val: {}\\n\".format(dropout_val))\n",
    "f.write(\"n_hidden_layer: {}\\n\".format(n_hidden_layer))\n",
    "f.close()\n",
    "\n",
    "filename = \"log_perf.txt\"\n",
    "f = open(filename, \"a\")\n",
    "f.write(\"\\n{}, {}, {}, {}, {}, {}, {}, {}, True\".format(nalm_model, statstr(metric_val_ml), seed_value, int(0.9*ilim), x_test.shape[0], dropout_val, spectrum, mult_fact))\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean and variance of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_camb = CreateCosmology(nside,lmax)\n",
    "\n",
    "n_new_x_test = 1000\n",
    "\n",
    "path_dir_data = \"data_FullSky_100_new_test\"\n",
    "if noisy_bool:\n",
    "    path_dir_data = path_dir_data + \"_noise\"\n",
    "path_dir_data = path_dir_data + \"/\"\n",
    "\n",
    "base_data_file = path_dir_data + \"data_FullSky_nside_{}_100_new_test\".format(nside)\n",
    "\n",
    "data_filename = base_data_file + \"_0.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a full sky map\n",
    "def CreateAnafastFullSky_(cl, nside, lmax, plot_results = False, noise_rms = 200):\n",
    "\n",
    "    map_ = hp.synfast(cl.T, nside, pixwin=False, verbose=False, new = True)\n",
    "    npix = 12 * nside ** 2\n",
    "    noise = np.random.randn(npix)*noise_rms\n",
    "    map_ = map_ + noise\n",
    "\n",
    "    # Anafast spectrum of this map\n",
    "    cl_ana, alm_ana = hp.anafast(map_, alm=True, lmax=lmax)\n",
    "\n",
    "    return alm_ana, cl_ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_type='Linear'\n",
    "\n",
    "theshape = Shape(shape_type, lmax, np.arange(0, lmax+1))\n",
    "theshape_ = np.ones(cl_camb.shape)\n",
    "for l in range(cl_camb.shape[0]):\n",
    "    theshape_[l, :] = theshape_[l, :]*theshape[l]\n",
    "\n",
    "# store/load the generated data into/from a file\n",
    "if not os.path.isfile(data_filename):\n",
    "        for i in range(n_new_x_test//100):\n",
    "            all_alm_ana_trans, all_cl_anafast_trans = np.zeros(shape=(3, 100, nalm))*1j, np.zeros(shape=(4, 100, nl))\n",
    "            for j in range(100):\n",
    "                [alm_ana, cl_ana] = CreateAnafastFullSky_(cl_camb * theshape_, nside, lmax, noise_rms = noise_rms)              \n",
    "                if j == 0:\n",
    "                    print(i*100)\n",
    "                all_alm_ana_trans[:, j, :] = alm_ana\n",
    "                all_cl_anafast_trans[:, j, :] = cl_ana[:4, :]\n",
    "            #\"\"\"\n",
    "            if not os.path.isdir(path_dir_data):\n",
    "                os.mkdir(path_dir_data)\n",
    "            data_filename = base_data_file + \"_{}.pickle\".format(i)\n",
    "            data_file = open(data_filename, \"wb\")\n",
    "            pickle.dump([all_alm_ana_trans, all_cl_anafast_trans, (cl_camb * theshape_).T], data_file)\n",
    "            data_file.close()\n",
    "            #\"\"\"\n",
    "\n",
    "all_cl_theo_new_test, all_alm_ana_new_test, all_cl_anafast_new_test = np.array([]), np.array([]), np.array([])\n",
    "for i in range(len(os.listdir(path_dir_data))):\n",
    "    data_filename = base_data_file + \"_{}.pickle\".format(i)\n",
    "    try:\n",
    "        data_file = open(data_filename, \"rb\")\n",
    "    except:\n",
    "        continue\n",
    "    [all_alm_ana_trans, all_cl_anafast_trans, cl_theo_new_test] = pickle.load(data_file)\n",
    "    if idx_cell < 3: # TT, EE or BB \n",
    "        all_alm_ana_trans, all_cl_anafast_trans, cl_theo_new_test = all_alm_ana_trans[idx_cell], all_cl_anafast_trans[idx_cell], cl_theo_new_test[idx_cell]\n",
    "    else: # We need alm of T and E\n",
    "        print(\"idx_cell >= 3 not implemented\")\n",
    "        exit()\n",
    "        all_cl_theo_binned_trans, all_alm_ana_trans, all_cl_anafast_binned_trans = all_cl_theo_binned_trans[idx_cell], all_alm_ana_trans[0], all_cl_anafast_binned_trans[idx_cell]\n",
    "        exit()\n",
    "    if i == 0:\n",
    "        all_alm_ana_new_test = all_alm_ana_trans.copy()\n",
    "        all_alm_ana_trans = []\n",
    "        all_cl_anafast_new_test = all_cl_anafast_trans.copy()\n",
    "        all_cl_anafast_trans = []\n",
    "    else:\n",
    "        all_alm_ana_new_test = np.append(all_alm_ana_new_test, all_alm_ana_trans, axis=0)\n",
    "        all_alm_ana_trans = []\n",
    "        all_cl_anafast_new_test = np.append(all_cl_anafast_new_test, all_cl_anafast_trans, axis=0)\n",
    "        all_cl_anafast_trans = []\n",
    "        #print(all_cl_anafast_new_test)\n",
    "    data_file.close()\n",
    "    if all_cl_anafast_new_test.shape[0] >= n_new_x_test:\n",
    "        break\n",
    "\n",
    "all_cl_theo_new_test = cl_theo_new_test\n",
    "\n",
    "print(all_cl_anafast_new_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting l range\n",
    "all_cl_theo_new_test = all_cl_theo_new_test[new_lmin:new_lmax+1]\n",
    "all_cl_anafast_new_test = all_cl_anafast_new_test[:, new_lmin:new_lmax+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "all_alm_ana_new_test = np.stack((all_alm_ana_new_test.real/max_alm_real, all_alm_ana_new_test.imag/max_alm_imag), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x_test = all_alm_ana_new_test\n",
    "new_y_test = all_cl_theo_new_test + noise_rms**2*4*np.pi/npix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network predictions\n",
    "result = model.predict(new_x_test, batch_size=128)/mult_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_result_np = np.mean(result, axis=0)\n",
    "std_result_np = np.std(result, axis=0)\n",
    "#\"\"\"\n",
    "mean_result = np.zeros(nl_used)\n",
    "mean_ana = np.zeros(nl_used)\n",
    "for i in range(n_new_x_test):\n",
    "    mean_result += result[i, :]\n",
    "    mean_ana += all_cl_anafast_new_test[i, :]\n",
    "mean_result /= n_new_x_test\n",
    "mean_ana /= n_new_x_test\n",
    "print(mean_result_np-mean_result)\n",
    "std_result = np.zeros(nl_used)\n",
    "std_ana = np.zeros(nl_used)\n",
    "for i in range(n_new_x_test):\n",
    "    std_result += (result[i, :]-mean_result)**2\n",
    "    std_ana += (all_cl_anafast_new_test[i, :]-mean_ana)**2\n",
    "std_result = np.sqrt(std_result/n_new_x_test)\n",
    "std_ana = np.sqrt(std_ana/n_new_x_test)\n",
    "#\"\"\"\n",
    "sample_variance_new_test = 2/(2*ll +1)new_y_test**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=120)\n",
    "if noisy_bool:\n",
    "    plt.plot(ll, ll * (ll + 1) / (2*np.pi) * new_y_test[:], label='Binned input spectra + noise')\n",
    "else:\n",
    "    plt.plot(ll, ll * (ll + 1) / (2*np.pi) * new_y_test[:], label='Binned input spectra')\n",
    "\n",
    "plt.errorbar(ll-0.2, ll * (ll + 1) / (2*np.pi) * mean_ana, yerr = ll * (ll + 1) / (2*np.pi) * std_ana, fmt='.', color=\"orange\", label='Mean Anafast')\n",
    "plt.errorbar(ll, ll * (ll + 1) / (2*np.pi) * mean_result, yerr = ll * (ll + 1) / (2*np.pi) * std_result, fmt='m.', label='Mean ML')\n",
    "plt.errorbar(ll+0.2, ll * (ll + 1) / (2*np.pi) * new_y_test[:], yerr = ll * (ll + 1) / (2*np.pi) * np.sqrt(sample_variance_new_test)[:], fmt='b.', label='Sample variance')\n",
    "\n",
    "plt.xlabel(r\"$\\ell$\")\n",
    "text = r\"$D_{\\ell}^{\" + spectrum + r\"}$\"\n",
    "plt.ylabel(text)\n",
    "plt.title(spectrum)\n",
    "plt.legend()\n",
    "figname = 'fig_prediction_mean.png'\n",
    "dest = os.path.join(path, figname)\n",
    "plt.savefig(dest, bbox_inches='tight')  # write image to file\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=120)\n",
    "if noisy_bool:\n",
    "    plt.plot(ll, ll * (ll + 1) / (2*np.pi) * new_y_test[:], label='Binned input spectra + noise')\n",
    "else:\n",
    "    plt.plot(ll, ll * (ll + 1) / (2*np.pi) * new_y_test[:], label='Binned input spectra')\n",
    "\n",
    "plt.errorbar(ll, ll * (ll + 1) / (2*np.pi) * mean_result, yerr = ll * (ll + 1) / (2*np.pi) * std_result, fmt='m.', label='Mean ML')\n",
    "\n",
    "plt.xlabel(r\"$\\ell$\")\n",
    "text = r\"$D_{\\ell}^{\" + spectrum + r\"}$\"\n",
    "plt.ylabel(text)\n",
    "plt.title(spectrum)\n",
    "plt.legend()\n",
    "figname = 'fig_prediction_mean_only_ML.png'\n",
    "dest = os.path.join(path, figname)\n",
    "plt.savefig(dest, bbox_inches='tight')  # write image to file\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
